---
layout: post
title: OpenAI and Google win gold at ICPC'25
date: 2025-09-20 10:00:00
categories: random
featured: true
thumbnail: assets/img/codeforces_pic.png 
---

<figure class="image" style="max-width: 100%; margin: 30px auto;">
  <img src="{{ '/assets/img/codeforces_pic.png' | relative_url }}" 
       alt="Codeforces ICPC'25" 
       style="width: 100%; height: auto; display: block; margin: 0 auto;">
  <figcaption style="text-align: center; font-style: italic; margin-top: 10px;">
    <a href="https://codeforces.com/blog/entry/59746" target="_blank">Read the full Codeforces blog post here</a>
  </figcaption>
</figure>

Most computer science students have heard of ICPC: the International Collegiate Programming Contest. It's a competition where teams write programs to solve algorithmic problems that must execute under strict time limits. This is popularly known as Competitive Programming (CP), done at various levels, with the ICPC World Finals being the highest stage (alongside the IOI).  

This year's ICPC was won by the St. Petersburg State University team. Interestingly, both OpenAI and Google's advanced reasoning models also secured a gold medal. Even more impressive: OpenAI's model solved all 12 problems perfectly, the first time in ICPC history (by humans or AI). Honestly, this is a big deal. But given the pace of AI progress (especially in coding), and the fact that these models have recently won gold at the IOI and IMO as well, it wasn't a huge surprise.  

But one thing I instantly remembered after reading this news was a Codeforces blog from seven years ago. Back in my undergrad days, I was also into CP, mostly on CodeChef and Codeforces. I never made it to the ICPC regionals (I was so disappointed that I never tried again üôÅ). The blog written by Near.ai discussed whether machines might one day solve CP problems on their own. Along with Near.ai, some academic labs were already exploring program synthesis with different techniques. At the time, I had no idea what those techniques were, but the thought felt both absurd and fascinating.  

Of course, computers beating humans wasn't new, Deep Blue had already defeated Kasparov decades ago. But chess has fixed rules, and a supercomputer can brute-force millions of moves. Competitive programming, on the other hand, often demands creativity that goes beyond algorithms and syntax. I remember telling my roommates how absurd it seemed that computers could ever solve such problems, and we laughed about it back then üòÖ.  

Fast forward to 18 September 2025: Google DeepMind and OpenAI announced that their reasoning models had won gold at the ICPC World Finals.
It's astonishing to see how far we've come in just a few years. Sure, LLMs still fail (a lot), and we love to complain‚Äîbut the pace of progress is undeniable. Let's see what's next.  

---

---

### Related blogs

- <https://codeforces.com/blog/entry/59746> 
-<https://blog.google/technology/google-deepmind/gemini-gold-icpc/>  
- <https://x.com/MostafaRohani/status/1968360976379703569>  
- <https://deepmind.google/discover/blog/advanced-version-of-gemini-with-deep-think-officially-achieves-gold-medal-standard-at-the-international-mathematical-olympiad/>
- <https://x.com/OpenAI/status/1954969035713687975>
- <https://deepmind.google/discover/blog/competitive-programming-with-alphacode/>

