<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Natual Language to LoRA Weights | Devesh Pant </title> <meta name="author" content="Devesh Pant"> <meta name="description" content="llm, research paper"> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" href="/assets/css/scholar-icons.css?62b2ac103a88034e6882a5be5f3e2772"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://pantdevesh.github.io/blog/2025/text2lora/"> <script src="/assets/js/theme.js?a81d82887dd692e91686b43de4542f18"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>
    initTheme();
  </script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Devesh</span> Pant </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item "> <a class="nav-link" href="/notes/index.html">notes </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Natual Language to LoRA Weights</h1> <p class="post-meta"> Created on July 02, 2025 </p> <p class="post-tags"> <a href="/blog/2025"> <i class="fa-solid fa-calendar fa-sm"></i> 2025 </a>   ·   <a href="/blog/tag/formatting"> <i class="fa-solid fa-hashtag fa-sm"></i> formatting</a>   <a href="/blog/tag/links"> <i class="fa-solid fa-hashtag fa-sm"></i> links</a>   ·   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <p>Recently Sakana AI released a paper called <a href="https://github.com/SakanaAI/text-to-lora" rel="external nofollow noopener" target="_blank">Text-to-Lora</a> to generate LoRA weights from the natural language task descriptions. There was another similar paper released called <a href="https://jerryliang24.github.io/DnD" rel="external nofollow noopener" target="_blank">Drag and Drop LLMs (DnD)</a> which proposes a different framework for a similar task. In this blog we will understand the working of these two approaches. Let us first understand the challenges with model finetuning for downstream tasks. In NLP (Natural Language Processing), a pre-trained language model is used for multiple downstream tasks. For example, T4 can be used for Question Answering, Named Entity Recognition, translation and many other tasks. However, if we want to finetune a large pre-trained model for a specific downstream application, then it would take lots of compute and might break the pre-trained model’s performance on other tasks. That is why, researchers came with an idea of finetuning only few parameters or adding additional task specific modules. There were lot’s of ideas around this, however in 2021, researchers from Microsoft proposed LoRA (Low Rank Adaptation) which gained widespread adoption not only for language models but across domains such vision transformers and diffusion models. (Existing Methods: Task specific adapters cause latency. Prefix finetuning is no good. )</p> <h3 id="lora-low-rank-adaptation">LoRA (Low Rank Adaptation)</h3> <p>LoRA is a method to efficiently finetune pre-trained models. Building upon the idea that weights of a large pre-trained model have low-intrinsic rank, the authors hypothesize that even the weight updates also have a low intrinsic-rank. They decompose the update to the pre-trained weight matrix del W into low rank decomposition: W0 + del(W) = W0 + BA <br> A forward pass would look like: h = W0x + del(w)x ===&gt; W0x + BAx Gradient updates are required only for the low rank matrix. Assume W0 has dim: 512x512, than A and B has dim: 512 x 8 and 8 x 512, thats 32 times less parameters than W0, now imagine that will the differnt weight matrices in the network. (No inference time latency )</p> <h4 id="challenges-with-lora">Challenges with LoRA</h4> <p>The papers highlight following challenges with LoRA:</p> <ul> <li>A new LoRA adapter need to be trained for each downstream task</li> <li>Though reduced trainable parameters, training LoRA adapter still takes significant time</li> </ul> <h4 id="text-to-lora">Text-to-Lora</h4> <p>— <em>Sakana AI</em> The authors try to answer two questions– <br></p> <ol> <li>Can we train neural networks to generte LoRA?</li> <li>Can these neural networks generate new LoRAs from unseen task descriptions during test-time?</li> </ol> <h5 id="generating-loras-from-natural-task-descriptors">Generating LoRAs from natural task descriptors</h5> <p>Training Data: <br> N datasets {D1, D2, …, Dn} each having a task descriptor Ti, which contains a general description of the dataset. <br> Training Objective for task_i: del(W)_i = argmin Loss_sft(Di, pretrained_llm, del(W)_i).</p> <h4 id="hypernetworks">Hypernetworks</h4> <p>The network used to synthesize the weights of the LoRA. Hypernetwork (2016) is used to generate parameters of another network or kind of compress different neural networks within it’s weights. Formally, given a layer descriptor vector v_l, hypernetwork generates parameter of layer l: W_l = h(v_l). The network is trained end-to-end on a downstream task.</p> <h3 id="text-to-lora-using-hypernetwork">Text-to-Lora using Hypernetwork</h3> <p>Given a target module (m) and layer index (l), text2Lora uses a hypernetwork to generate low-rank matrices A and B, based on a task descriptor $z^{i}\in Z^{i}$ of task $t^{i}$ :<br> \(\Delta W_{m,l}^{i} = h_{\theta}(\phi_{m,l}^{i})\)</p> <p>\(\phi_{m,l}^{i} = \text{concat}[f(z^{i}), E[m], E[l]]\) Where f is a function to generate embedding of the task description, typically $\text{[CLS]}$ token of a bi-directional transformer or last token activation of an LLM.<br> E is a learnable embedding dictionary indexed by either module $m$ or layer index $l$. <br> Supervised finetuning objective for T2L is: \(\Theta = \arg\min_{\theta}(\mathcal{L}_{\mathrm{SFT}}(D^{i},\psi,h_{\theta}(\phi^{i})))\)</p> <blockquote> <p><strong>Note:</strong>: We can batch $m$ and $l$, that allows us to generate the parameters of all modules and layers in a single forward pass.</p> </blockquote> <h4 id="different-hypernetwork-architectures">Different Hypernetwork Architectures:</h4> <p>Authors propose three architecures: L (Large), M (Meidum) and S (Small).</p> <ul> <li> <p><strong>L Architecture</strong>: Final layer outputs $A$ and $B$ matrices simultaneously. Output parameters: \(|\theta_{head}| = d_{head}\times 2 \times r \times d\) where $d_{head}$ is the dimension of the last MLP, $r$ is the rank of the matrices $A$ and $B$ and $d$ is the dimension of weight matrix $W$.</p> </li> <li> <p><strong>M Architecture</strong>: Final layer outputs either $A$ and $B$ matricx depending on the input embedding, meaning that the output layer is shared between $A$ and $B$. Output parameters: \(|\theta_{head}| = d_{head} \times r \times d\)</p> </li> <li> <p><strong>S Architecture</strong>: Final layer outputs $A$ and $B$ matrices simultaneously. Output parameters: \(|\theta_{head}| = d_{head}\times d\) where $d_{emb}$ is the dimension of weight matrix $W$. This variation has strongest inductive bias.</p> </li> </ul> <p>All of these architecures can generate all LoRAs in a single forward pass by batching the input text embeddings.</p> <h4 id="training-of-hyperparameters">Training of Hyperparameters</h4> <p>There are two possible ways of training the hypernetwork. One is by reconstructing trained LoRAs and other is via Supervised Finetuning.</p> <ul> <li> <strong>Training Text-to-LoRA via LoRA Reconstruction:</strong> The network is trained to reconstruct LoRA matrices. We can either use LoRAs from a pre-trained library or first perform peft training to generate LoRAs than train our hypernetwork. T2L can be trained using either one-hot vector embeddings or task description in natural languages. However, there is a downside with training using one-hot embeddings, as we won’t be able to use the network in a zero-shot setting. <br> Given a suitable library of LoRA adapters $\Omega$, the reconstruction loss for T2L can be written as: \(\mathcal L(\Omega,\theta) = \mathbb E_{\Delta W^i \sim \Omega} (\Delta W^i - h_{\theta}(\phi^i))\)</li> <li> <strong>Training T2L via end-to-end finetuning:</strong> One issue with the prior approach is if we have reconstructed two LoRAs related to similar tasks, whose weights $\Delta W1$ and $\Delta W2$ reside in different minima, then trained hypernetwork might not generalize on the similar tasks. We can avoid it by direclty finetuning T2L on the target task, so that it implicitly learns to cluster the similar LoRAs.</li> </ul> <p>Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. <a href="https://www.pinterest.com" rel="external nofollow noopener" target="_blank">Pinterest</a> DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade <a href="https://en.wikipedia.org/wiki/Cold-pressed_juice" rel="external nofollow noopener" target="_blank">cold-pressed</a> meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.</p> <h4 id="hipster-list">Hipster list</h4> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> <h4 id="check-list">Check List</h4> <ul class="task-list"> <li class="task-list-item"> <input type="checkbox" class="task-list-item-checkbox" disabled checked>Brush Teeth</li> <li class="task-list-item"> <input type="checkbox" class="task-list-item-checkbox" disabled>Put on socks <ul class="task-list"> <li class="task-list-item"> <input type="checkbox" class="task-list-item-checkbox" disabled checked>Put on left sock</li> <li class="task-list-item"> <input type="checkbox" class="task-list-item-checkbox" disabled>Put on right sock</li> </ul> </li> <li class="task-list-item"> <input type="checkbox" class="task-list-item-checkbox" disabled checked>Go to school</li> </ul> <p>Hoodie Thundercats retro, tote bag 8-bit Godard craft beer gastropub. Truffaut Tumblr taxidermy, raw denim Kickstarter sartorial dreamcatcher. Quinoa chambray slow-carb salvia readymade, bicycle rights 90’s yr typewriter selfies letterpress cardigan vegan.</p> <hr> <p>Pug heirloom High Life vinyl swag, single-origin coffee four dollar toast taxidermy reprehenderit fap distillery master cleanse locavore. Est anim sapiente leggings Brooklyn ea. Thundercats locavore excepteur veniam eiusmod. Raw denim Truffaut Schlitz, migas sapiente Portland VHS twee Bushwick Marfa typewriter retro id keytar.</p> <blockquote> <p>We do not grow absolutely, chronologically. We grow sometimes in one dimension, and not in another, unevenly. We grow partially. We are relative. We are mature in one realm, childish in another. —Anais Nin</p> </blockquote> <p>Fap aliqua qui, scenester pug Echo Park polaroid irony shabby chic ex cardigan church-key Odd Future accusamus. Blog stumptown sartorial squid, gastropub duis aesthetic Truffaut vero. Pinterest tilde twee, odio mumblecore jean shorts lumbersexual.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://blog.google/technology/ai/google-gemini-update-flash-ai-assistant-io-2024/" target="_blank" rel="external nofollow noopener">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="https://medium.com/@al-folio/displaying-external-posts-on-your-al-folio-blog-b60a1d241a0a?source=rss-17feae71c3c4------2" target="_blank" rel="external nofollow noopener">Displaying External Posts on Your al-folio Blog</a> <svg width="1rem" height="1rem" viewbox="0 0 30 30" xmlns="http://www.w3.org/2000/svg"> <path d="M17 13.5v6H5v-12h6m3-3h6v6m0-6-9 9" class="icon_svg-stroke" stroke="#999" stroke-width="1.5" fill="none" fill-rule="evenodd" stroke-linecap="round" stroke-linejoin="round"></path> </svg> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/useful-links/">Curated List of Useful Blogs and Videos</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2025/plotly/">a post with plotly.js</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/photo-gallery/">a post with image galleries</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2025 Devesh Pant. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js?a0db7e5d5c70cc3252b3138b0c91dcaf" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?c8a01c11a92744d44b093fc3bda915df" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script src="/assets/js/mathjax-setup.js?a5bb4e6a542c546dd929b24b8b236dfd"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script defer src="/assets/js/progress-bar.js?2f30e0e6801ea8f5036fa66e1ab0a71a" type="text/javascript"></script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>
    addBackToTop();
  </script> </body> </html>